{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleanup_All_Rolls_TalDorei",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SZ6bTCEKS-s7c7-IdqN1j3o16k28M3Ea",
      "authorship_tag": "ABX9TyNmFpBumah9cO7DGtDq3DRE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onishchenkoar/dungeons-and-dragons-and-probabilities/blob/main/Cleanup_All_Rolls_TalDorei.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvTnOvzMctID"
      },
      "source": [
        "# Cleanup of _All Rolls - Tal'Dorei_ table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7rJxiGC1eq6"
      },
      "source": [
        "I'm using [*All Rolls - Tal'Dorei* table]((https://docs.google.com/spreadsheets/d/1OEg29XbL_YpO0m5JrLQpOPYTnxVsIg8iP67EYUrtRJg/edit?usp=sharing) for a personal project of mine. I've found some inconsistencies in the document; so here is my attempt to improve it. I have not gone verifying the data row-by-row, but rather employed some consistency checks on each column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujiAaRIdmjyK"
      },
      "source": [
        "## Couple of notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m31HjfyGhqPE"
      },
      "source": [
        "### Note 1\n",
        "In the code, whenever there is a row number (for example, 3942 in `df.loc[3942, 'Time']`), add 2 to it to find a corresponding row in the [original document]((https://docs.google.com/spreadsheets/d/1OEg29XbL_YpO0m5JrLQpOPYTnxVsIg8iP67EYUrtRJg/edit?usp=sharing). This happens because in Pandas indexing starts from 0 and the header is not counted as a row. In Google Spreadsheets, indexing starts from 1 and the header is one of the rows. So, whenever row 3942 (like in the example above) is addressed in the code, it is row 3944 in the Google doc.\n",
        "\n",
        "### Note 2\n",
        "There are a number of empty rows (3032, 3324 are notes on missing audio/video; 7243 to 7248 seem to be some artifact of manual processing). I noticed them in the middle of my process and decided to keep them until the very end, so I don't mess the indexing.\n",
        "\n",
        "### Note 3\n",
        "I'm structuring the code so that only parts that make changes to the table are executable. I'm formatting all code involving the search for mistakes as Markdown cells. I did it this way, because a) when searching, the output is cumbersome, b) finding typos and inconsistencies involves a lot of manual labor that cannot be captured in code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqc4JtkoY3fI"
      },
      "source": [
        "## Imports and initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmCVpjYSY7B6"
      },
      "source": [
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 15000)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 150)\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "\n",
        "df = pd.read_csv(\"drive/MyDrive/All Rolls - Tal'Dorei - All Episodes.csv\",\n",
        "                 skipinitialspace=True\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvGkgq2OsqUM"
      },
      "source": [
        "## *Episode* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCTjz1lM3SJh"
      },
      "source": [
        "One typo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywptZjRr3bAK"
      },
      "source": [
        "# Correct typos:\n",
        "df.loc[858, 'Episode'] = '8' # was 9"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYNDAxOqn3Oz"
      },
      "source": [
        "The Episode column needs a change of format, so that it can be sorted alphabetically.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_lOQC-n6Ig"
      },
      "source": [
        "# Format Episode column, so that it is appropriate for sorting.\n",
        "# Episode '2' becomes 'C1E002'; episode '31 p1' becomes 'C1E031 p1'.\n",
        "# This is the formatting used in Campaign 2 table of rolls.\n",
        "df['Episode'] = df['Episode'].astype(str)\n",
        "df['Episode'] = df['Episode'].map(lambda x: 'C1E' + x.zfill(3\n",
        "                                                            if len(x) <= 3\n",
        "                                                            else 6 \n",
        "                                                           )\n",
        "                                 )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqENsx-rbDRA"
      },
      "source": [
        "## *Time* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iQNMF96Xb-I"
      },
      "source": [
        "### Malformed timestamps\n",
        "\n",
        "I found malformed timestamps using the following code:\n",
        "```python\n",
        "for i, t in df['Time'].items():\n",
        "  try:\n",
        "    pd.to_datetime(t, format='%H:%M:%S')\n",
        "  except:\n",
        "    print(i, t)\n",
        "\n",
        "# >>> 3942 1:10\n",
        "#     8023 2:12;26\n",
        "#     9282 1:27:43)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htqSS0Z_ZCWD"
      },
      "source": [
        "The code to correct them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3myCux4Yy3Y"
      },
      "source": [
        "# Correct malformed timestamps:\n",
        "df.loc[3942, 'Time'] = '1:10:00' # was 1:10\n",
        "df.loc[8023, 'Time'] = '2:12:26' # was 2:12;26\n",
        "df.loc[9282, 'Time'] = '1:27:43' # was 1:27:43)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IymGs15Zczt"
      },
      "source": [
        "### Typos in the timestamps\n",
        "\n",
        "I checked whether the timestamps within one episode are always increasing (or same).\n",
        "\n",
        "```python\n",
        "temp = df[['Episode', 'Time']].copy().dropna()\n",
        "temp.loc[:, 'Time'] = pd.to_datetime(temp['Time']).dt.time\n",
        "\n",
        "next_time_is_higher_or_same = temp.iloc[1:, 1].to_numpy() >= temp.iloc[:-1, 1].to_numpy()\n",
        "next_ep_is_higher = temp.iloc[1:, 0].to_numpy() > temp.iloc[:-1, 0].to_numpy()\n",
        "monotonic_row_mask = np.logical_xor(next_time_is_higher_or_same, next_ep_is_higher)\n",
        "monotonic_row_mask = np.concatenate(([True], monotonic_row_mask))\n",
        "# I have to augment the mask because I used dropna() when assigning temp\n",
        "# and rows 3032, 3324, 7246-7249 are empty.\n",
        "monotonic_row_mask = np.concatenate((monotonic_row_mask[:3031],\n",
        "                                     [True],\n",
        "                                     monotonic_row_mask[3031:]\n",
        "                                    )\n",
        "                                   )\n",
        "monotonic_row_mask = np.concatenate((monotonic_row_mask[:3323],\n",
        "                                     [True],\n",
        "                                     monotonic_row_mask[3323:]\n",
        "                                    )\n",
        "                                   )\n",
        "monotonic_row_mask = np.concatenate((monotonic_row_mask[:7243],\n",
        "                                     [True, True, True, True, True],\n",
        "                                     monotonic_row_mask[7243:]\n",
        "                                    )\n",
        "                                   )\n",
        "idx = np.where(~monotonic_row_mask)[0]\n",
        "\n",
        "print(idx)\n",
        "print()\n",
        "print(len(idx))\n",
        "\n",
        "# >>>[  336   520   804  1061  1120  1183  1535  1611  1681  1826  1834  2045\n",
        "#  ...    \n",
        "#  13331 13333 13335 13346 13376 13412 13430 13505]\n",
        "\n",
        "# 140\n",
        "```\n",
        "\n",
        "In 140 cases, they are not. Sometimes, those are typos, sometimes, those are just rows out of order.\n",
        "\n",
        "The code that corrects the typos I managed to find:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNLI2RhYa0SG"
      },
      "source": [
        "# Correct mistyped timestamps:\n",
        "df.loc[[334, 335], \"Time\"] = \"1:55:21\" # was 1:56:21\n",
        "df.loc[520, \"Time\"] = \"2:52:59\" # was 2:22:59  \n",
        "df.loc[803, \"Time\"] = \"3:28:00\" # was 3:39:00\n",
        "df.loc[1120, \"Time\"] = \"1:17:18\" # was 1:17:13\n",
        "df.loc[1183, \"Time\"] = \"0:41:37\" # was 0:31:37\n",
        "df.loc[1534, \"Time\"] = \"2:17:22\" # was 2:27:22\n",
        "df.loc[1610, \"Time\"] = \"0:38:27\" # was 0:38:47\n",
        "df.loc[1680, \"Time\"] = \"2:39:01\" # was 2:39:04\n",
        "df.loc[1826, \"Time\"] = \"2:51:01\" # was 2:50:15\n",
        "df.loc[1834, \"Time\"] = \"2:57:25\" # was 2:57:23\n",
        "df.loc[2518, \"Time\"] = \"3:25:02\" # was 3:35:02\n",
        "df.loc[3526, \"Time\"] = \"1:13:04\" # was 1:03:04\n",
        "df.loc[3571, \"Time\"] = \"1:53:06\" # was 1:53:16\n",
        "df.loc[3611, \"Time\"] = \"0:02:12\" # was 0:05:26\n",
        "df.loc[3622, \"Time\"] = \"0:28:22\" # was 0:28:23\n",
        "df.loc[3824, \"Time\"] = \"1:20:10\" # was 1:18:28\n",
        "df.loc[4127, \"Time\"] = \"2:33:15\" # was 2:30:55\n",
        "df.loc[4277, \"Time\"] = \"0:52:06\" # was 0:54:06\n",
        "df.loc[4494, 'Time'] = '2:52:32' # was 2:53:32\n",
        "df.loc[4614, \"Time\"] = \"2:19:48\" # was 2:19:28\n",
        "df.loc[4893, \"Time\"] = \"0:52:01\" # was 0:51:01\n",
        "df.loc[5108, \"Time\"] = \"3:05:10\" # was 3:01:10\n",
        "df.loc[5118, \"Time\"] = \"1:09:58\" # was 1:00:58\n",
        "df.loc[5585, \"Time\"] = \"2:38:14\" # was 2:28:14\n",
        "df.loc[5592, \"Time\"] = \"2:42:15\" # was 1:42:15\n",
        "df.loc[5636, \"Time\"] = \"1:34:30\" # was 1:32:30\n",
        "df.loc[[5674, 5675], \"Time\"] = \"2:45:47\" # was 2:52:47\n",
        "df.loc[5707, \"Time\"] = \"1:51:54\" # was 1:51:14\n",
        "df.loc[5905, \"Time\"] = \"1:54:47\" # was 1:54:17\n",
        "df.loc[5936, \"Time\"] = \"3:03:57\" # was 3:05:59\n",
        "df.loc[5937, \"Time\"] = \"3:03:59\" # was 3:05:59\n",
        "df.loc[5941, \"Time\"] = \"3:04:47\" # was 3:04:04\n",
        "df.loc[5956, \"Time\"] = \"3:08:53\" # was 2:08:53\n",
        "df.loc[5975, \"Time\"] = \"3:32:27\" # was 3:32:37\n",
        "df.loc[6022, \"Time\"] = \"3:58:26\" # was 2:58:26\n",
        "df.loc[6193, \"Time\"] = \"1:15:20\" # was 1:50:20\n",
        "df.loc[6325, \"Time\"] = \"1:00:31\" # was 1:01:31  \n",
        "df.loc[[6359, 6360], \"Time\"] = \"1:41:48\" # was 1:45:48\n",
        "df.loc[6492, \"Time\"] = \"2:42:53\" # was 3:42:53 \n",
        "df.loc[6536, \"Time\"] = \"3:28:13\" # was 3:18:13\n",
        "df.loc[[6705, 6706, 6707, 6709, 6710, 6711], \"Time\"] = \"2:42:10\" # was 2:40:10\n",
        "df.loc[6741, \"Time\"] = \"3:15:33\" # was 3:14:52\n",
        "df.loc[6742, \"Time\"] = \"3:15:45\" # was 3:05:42\n",
        "df.loc[7187, \"Time\"] = \"2:54:57\" # was 2:54:27\n",
        "df.loc[7404, \"Time\"] = \"0:37:30\" # was 0:27:30\n",
        "df.loc[7380, \"Time\"] = \"0:11:18\" # was 0:11:48\n",
        "df.loc[7392, \"Time\"] = \"0:27:28\" # was 0:27:56\n",
        "df.loc[[7395, 7396], \"Time\"] = \"0:27:33\" # was 0:27:31\n",
        "df.loc[7410, \"Time\"] = \"0:42:42\" # was 0:42:32\n",
        "df.loc[7412, \"Time\"] = \"0:49:21\" # was 0:42:21\n",
        "df.loc[7506, \"Time\"] = \"3:00:23\" # was 2:00:23\n",
        "df.loc[7521, \"Time\"] = \"3:08:23\" # was 3:11:23\n",
        "df.loc[7535, \"Time\"] = \"3:15:49\" # was 3:15:37\n",
        "df.loc[7547, \"Time\"] = \"3:32:04\" # was 3:31:54\n",
        "df.loc[7560, \"Time\"] = \"3:52:08\" # was 3:22:12\n",
        "df.loc[7959, \"Time\"] = \"1:18:50\" # was 1:48:50\n",
        "df.loc[7960, \"Time\"] = \"1:18:56\" # was 1:48:56\n",
        "df.loc[7991, \"Time\"] = \"1:49:57\" # was 1:49:37\n",
        "df.loc[8087, \"Time\"] = \"3:23:15\" # was 3:27:15\n",
        "df.loc[8247, \"Time\"] = \"0:43:03\" # was 0:32:03\n",
        "df.loc[8379, \"Time\"] = \"3:57:09\" # was 2:57:09\n",
        "df.loc[8397, \"Time\"] = \"4:18:15\" # was 4:19:20\n",
        "df.loc[8470, \"Time\"] = \"2:47:12\" # was 2:27:12\n",
        "df.loc[8472, \"Time\"] = \"2:56:44\" # was 2:45:44\n",
        "df.loc[8892, \"Time\"] = \"2:26:50\" # was 2:25:50\n",
        "df.loc[9239, \"Time\"] = \"0:27:14\" # was 2:27:14 \n",
        "df.loc[9309, \"Time\"] = \"2:22:04\" # was 2:02:04\n",
        "df.loc[9493:9500, \"Time\"] = \"2:46:09\" # was 2:42:29\n",
        "df.loc[[9631, 9632], \"Time\"] = \"0:37:15\" # was 0:37:35\n",
        "df.loc[9694, \"Time\"] = \"1:38:22\" # was 1:38:32\n",
        "df.loc[9751, \"Time\"] = \"2:36:59\" # was 2:26:59\n",
        "df.loc[9776, \"Time\"] = \"3:17:01\" # was 3:17:22 \n",
        "df.loc[9852, \"Time\"] = \"0:27:43\" # was 0:26:43\n",
        "df.loc[9876, \"Time\"] = \"0:47:36\" # was 0:43:46\n",
        "df.loc[10142, \"Time\"] = \"2:31:13\" # was 2:26:23\n",
        "df.loc[10257, \"Time\"] = \"3:54:40\" # was 3:54:17\n",
        "df.loc[10322, \"Time\"] = \"4:41:45\" # was 4:01:35\n",
        "df.loc[10372, \"Time\"] = \"5:18:30\" # was 5:18:17\n",
        "df.loc[10767, \"Time\"] = \"3:03:00\" # was 3:02:26\n",
        "df.loc[10834, \"Time\"] = \"3:54:07\" # was 2:54:07\n",
        "df.loc[10870, \"Time\"] = \"1:07:55\" # was 1:32:15\n",
        "df.loc[10895, \"Time\"] = \"3:34:09\" # was 3:24:09\n",
        "df.loc[11196, \"Time\"] = \"3:59:50\" # was 3:59:15\n",
        "df.loc[11284, \"Time\"] = \"3:05:21\" # was 2:05:21\n",
        "df.loc[11538, \"Time\"] = \"2:29:18\" # was 2:29:28 \n",
        "df.loc[11651, \"Time\"] = \"2:38:02\" # was 2:39:02\n",
        "df.loc[[11698, 11699], \"Time\"] = \"3:29:05\" # was 3:28:05\n",
        "df.loc[11701, \"Time\"] = \"3:30:33\" # was 3:20:23\n",
        "df.loc[11800, \"Time\"] = \"1:12:46\" # was 1:21:46\n",
        "df.loc[11858, \"Time\"] = \"2:16:55\" # was 2:15:55\n",
        "df.loc[11988, \"Time\"] = \"1:25:52\" # was 1:24:42\n",
        "df.loc[12016, \"Time\"] = \"2:25:43\" # was 2:25:42\n",
        "df.loc[12027, \"Time\"] = \"2:32:09\" # was 1:32:09\n",
        "df.loc[12558, \"Time\"] = \"2:51:14\" # was 2:21:14\n",
        "df.loc[12681, \"Time\"] = \"1:46:34\" # was 1:45:34\n",
        "df.loc[13144, \"Time\"] = \"0:16:40\" # was 0:16:50\n",
        "df.loc[13346, \"Time\"] = \"3:35:28\" # was 3:25:28\n",
        "df.loc[13411, \"Time\"] = \"4:17:56\" # was 5:17:56\n",
        "df.loc[13430, \"Time\"] = \"4:38:29\" # was 4:38:28\n",
        "df.loc[13505, \"Time\"] = \"2:13:15\" # was 1:13:15 \n",
        "df.loc[13506, \"Time\"] = \"2:19:35\" # was 1:19:35"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-noll8KrsZF1"
      },
      "source": [
        "### Mismatching timestamps for rolls with advantage/disadvantage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oVWmuyza31I"
      },
      "source": [
        "I've noticed that, in general, rolls with advantage and disadvantage come in pairs and have the same timestamp, disregarding the actual timing for one of them.\n",
        "\n",
        "I have found three timestamps violating this rule.\n",
        "\n",
        "Correction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7i7Pu-ZeUhm"
      },
      "source": [
        "# Replace timestamps that do not match their advantage/disadvantage counterpart:\n",
        "df.loc[136, 'Time'] = '2:05:44' # was 2:05:38\n",
        "df.loc[1527, 'Time'] = '2:13:09' # was 2:12:48\n",
        "df.loc[10975, 'Time'] = '1:30:32' # was 1:30:31"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHzcO2JBsSss"
      },
      "source": [
        "## *Character* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrpLmAl8HhW6"
      },
      "source": [
        "Again, looked through the unique values of the column.\n",
        "```python\n",
        "sorted(df['Character'].dropna().unique())\n",
        "\n",
        "# >>> ['1 freq', '20 freq', 'Arkhan', 'Doty', 'Garthok', 'Gern',\n",
        "#      'Gloomstalker', 'Grenade', 'Grog', 'Kashaw', 'Kerrek',\n",
        "#      'Keyleth', 'Lillith', 'Lionel', 'Lyra', 'Others', 'PIke',\n",
        "#      'Percy', 'Pike', 'Scanlan', 'Shale', 'Shark', 'Sprigg',\n",
        "#      'Taryon', 'Thorbir', 'Tiberius', 'Tibierus', 'Tova',\n",
        "#      'Trinket', \"Vax'ildan\", \"Vex'ahlia\", 'Zahra']\n",
        "```\n",
        "\n",
        "I'll remove the rows that contain '1 freq' and '20 freq' later. For now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wiy7VOnINtp"
      },
      "source": [
        "# Correct mistyped character names:\n",
        "to_replace = {\n",
        "  'PIke' : 'Pike',\n",
        "  'Tibierus' : 'Tiberius',\n",
        "}\n",
        "df['Character'].replace(to_replace, inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUXI4iGCeXvf"
      },
      "source": [
        "## *Type of Roll* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZaDOMnhegCm"
      },
      "source": [
        "There are a few typos (like \"Steath\") and inconsistencies (two names for the same thing, like \"Wisdom Save\" and \"Wisdom Saving\").\n",
        "\n",
        "I found them by looking through unique values in the column.\n",
        "```python\n",
        "sorted(df['Type of Roll'].dropna().unique())\n",
        "\n",
        "# >>> 'Acrobatics',\n",
        "#     'Alchemy?',\n",
        "#     'Animal Handling',\n",
        "#     ...\n",
        "#     'Wisdom Save',\n",
        "#     'Wisdom Save?',\n",
        "#     'Wisdom Saving'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJJnYWJJngBU"
      },
      "source": [
        "# Correcting typos and inconsistent naming in Type of Roll column:\n",
        "to_replace = {\n",
        "  'Steath' : 'Stealth',\n",
        "  'Dex Save' : 'Dexterity Save',\n",
        "  'Wisdom Saving' : 'Wisdom Save',\n",
        "  'Beard' : 'Beard Check',\n",
        "  'Ressurrection Roll' : 'Resurrection Roll',\n",
        "  'Fix' : 'Tinkering',\n",
        "  'Spell Effect' : 'Intelligence',\n",
        "  'Skill' : 'Constitution Save',\n",
        "}\n",
        "df['Type of Roll'].replace(to_replace, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74UJrUGMsIml"
      },
      "source": [
        "## *Total Value* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obG2HwSv0exT"
      },
      "source": [
        "I've looked through the unique values in the column.\n",
        "\n",
        "```python\n",
        "sorted(df['Total Value'].dropna().astype(str).unique())\n",
        "\n",
        "# >>> ['--', '-1', '0', '1', '10', '102', '109', '11', '12', '13', '14',\n",
        "#      '15', '16', '17', '18', '19', '2', '20', '20+', '21', '22', '23',\n",
        "#      ...\n",
        "#      'Nat3', 'Nat4', 'Nat6', 'Nat8', 'Natural 1', 'Natural 20',\n",
        "#      'Success', 'Unkknown', 'Unknown', 'Unnknown', 'unknown']\n",
        "```\n",
        "\n",
        "There are a number of issues:\n",
        "1. Typos.\n",
        "1. Inconsistent notation.\n",
        "1. Natural value of a roll is written instead of its total.\n",
        "1. Total value is missing despite natural value being present.\n",
        "\n",
        "Correction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8xI83UuSPNU"
      },
      "source": [
        "# Replace inconsistent names and typos:\n",
        "to_replace = {\n",
        "  'Natural 20' : 'Nat20',\n",
        "  'Natural 1' : 'Nat1',\n",
        "  'Nat' : 'Nat1',\n",
        "  '20+' : '>20',\n",
        "  '70ish' : '>70',\n",
        "  'Unkknown' : 'Unknown',\n",
        "  'Unnknown' : 'Unknown',\n",
        "  'unknown' : 'Unknown',\n",
        "}\n",
        "df['Total Value'].replace(to_replace, inplace=True)\n",
        "\n",
        "# Remove Nat20= to leave pure values:\n",
        "mask = df['Total Value'].str.contains('Nat20=', na=False)\n",
        "df.loc[mask, 'Total Value'] = \\\n",
        "  df.loc[mask, 'Total Value'].str.replace('Nat20=', '')\n",
        "\n",
        "# Remove Nat1= to leave pure values:\n",
        "mask = df['Total Value'].str.contains('Nat1=', na=False)\n",
        "df.loc[mask, 'Total Value'] = \\\n",
        "  df.loc[mask, 'Total Value'].str.replace('Nat1=', '')\n",
        "\n",
        "# Calculate missing total values from natural values:\n",
        "df.loc[213, 'Total Value'] = '8' # was Nat2\n",
        "df.loc[251, 'Total Value'] = '18' # was Nat16\n",
        "df.loc[252, 'Total Value'] = '15' # was Nat13\n",
        "df.loc[746, 'Total Value'] = '10' # was Nat3\n",
        "df.loc[776, 'Total Value'] = '6' # was Nat2\n",
        "df.loc[811, 'Total Value'] = '13' # was Nat2\n",
        "df.loc[1162, 'Total Value'] = '13' # was Nat2\n",
        "df.loc[1173, 'Total Value'] = '17' # was Nat4\n",
        "df.loc[1393, 'Total Value'] = '31' # was Nat19\n",
        "df.loc[1420, 'Total Value'] = '29' # was Nat17\n",
        "df.loc[1446, 'Total Value'] = '9' # was --\n",
        "df.loc[2216, 'Total Value'] = '1' # was --\n",
        "df.loc[2331, 'Total Value'] = '21' # was Nat19\n",
        "df.loc[2679, 'Total Value'] = '28' # was Nat17\n",
        "df.loc[3045, ['Total Value', 'Natural Value']] = ('18', '13') # was Nat18\n",
        "df.loc[3158, 'Total Value'] = '28' # was Nat18, 28\n",
        "df.loc[3786, 'Total Value'] = '7' # was Nat3\n",
        "df.loc[3854, 'Total Value'] = '12' # was Nat3\n",
        "df.loc[3956, 'Total Value'] = '4' # was Nat2\n",
        "df.loc[4077, 'Total Value'] = '23' # was Nat 18\n",
        "df.loc[5395, 'Total Value'] = '26' # was Nat13\n",
        "df.loc[9658, 'Total Value'] = '13' # was Nat3\n",
        "df.loc[9659, 'Total Value'] = '23' # was Nat13\n",
        "df.loc[9736, 'Total Value'] = '21' # was Nat6\n",
        "df.loc[10266, 'Total Value'] = '20' # was Nat15\n",
        "df.loc[11964, 'Total Value'] = '31' # was Nat19\n",
        "df.loc[12506, 'Total Value'] = '10' # was Nat2\n",
        "df.loc[12560, 'Total Value'] = '17' # was Nat6\n",
        "df.loc[12581, 'Total Value'] = '12' # was Nat3\n",
        "df.loc[12588, 'Total Value'] = '19' # was Nat8\n",
        "df.loc[12662, 'Total Value'] = '33' # was Nat19\n",
        "df.loc[12683, 'Total Value'] = '31' # was Nat19\n",
        "df.loc[12757, 'Total Value'] = '17' # was Nat17\n",
        "\n",
        "df.loc[4008, 'Total Value'] = '25' # was null\n",
        "df.loc[4009, 'Total Value'] = '9' # was null\n",
        "df.loc[4010, 'Total Value'] = '9' # was null\n",
        "df.loc[4158, 'Total Value'] = '11' # was null\n",
        "df.loc[5248, ['Total Value', 'Natural Value']] = ('5', '5') # was null, 0\n",
        "df.loc[5433, 'Total Value'] = '26' # was null\n",
        "df.loc[10726, 'Total Value'] = '23' # was null\n",
        "df.loc[11023, 'Total Value'] = '22' # was null\n",
        "df.loc[11024, 'Total Value'] = '24' # was null\n",
        "df.loc[11025, 'Total Value'] = '28' # was null\n",
        "df.loc[11170, 'Total Value'] = '18' # was null\n",
        "df.loc[11267, ['Total Value', 'Natural Value']] = ('17', '7') # was null, Unknown\n",
        "df.loc[11285, 'Total Value'] = '27' # was null\n",
        "df.loc[11307, 'Total Value'] = '22' # was null\n",
        "df.loc[11332, 'Total Value'] = '12' # was null\n",
        "df.loc[11342, 'Total Value'] = '31' # was null\n",
        "df.loc[[11671, 12220, 12223], 'Total Value'] = 'Nat19' # was null\n",
        "df.loc[12194, 'Total Value'] = '2' # was null\n",
        "df.loc[12335, 'Total Value'] = '14' # was null\n",
        "df.loc[12385, 'Total Value'] = '32' # was null\n",
        "df.loc[12767, ['Total Value', 'Natural Value']] = ('11', '11') # was Unknown, Unknown"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqMeb6B-szMt"
      },
      "source": [
        "## *Natural Value* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKv2ONA4T6uC"
      },
      "source": [
        "```python\n",
        "sorted(df['Natural Value'].dropna().astype(str).unique())\n",
        "\n",
        "# >>> ['#REF!', '--', '-1', '-4', '0', '1', '10', '11', '12', '13', '14',\n",
        "#      '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24',\n",
        "#      '25', '26', '3', '4', '5', '6', '7', '8', '9', 'Uknown', 'Unknown',\n",
        "#      'Unkown', 'unknown']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arGG83B0UkVz"
      },
      "source": [
        "# Correcting typos and inconsistent naming in Natural Value column:\n",
        "to_replace = {\n",
        "  '--' : np.nan,\n",
        "  'Uknown' : 'Unknown',\n",
        "  'Unkown' : 'Unknown',\n",
        "  'unknown' : 'Unknown',\n",
        "}\n",
        "df['Natural Value'].replace(to_replace, inplace=True)\n",
        "\n",
        "df.loc[5811, 'Natural Value'] = '19' # was #REF!"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK0NpjSws7Fo"
      },
      "source": [
        "## *Crit?* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeOLr82qV_sF"
      },
      "source": [
        "```python\n",
        "sorted(df['Crit?'].dropna().astype(str).unique())\n",
        "\n",
        "# >>> ['--', '1', 'Y']\n",
        "```\n",
        "\n",
        "'--' should be an empty cell; 1 should be Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUCg4V7TW1xJ"
      },
      "source": [
        "# Correct inconsistent notation:\n",
        "to_replace = {\n",
        "  '1' : 'Y',\n",
        "  '--' : np.nan\n",
        "}\n",
        "df['Crit?'].replace(to_replace, inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuCt2yWPtJ5g"
      },
      "source": [
        "## *# Kills* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmQIgenWBS4L"
      },
      "source": [
        "```python\n",
        "sorted(df['# Kills'].dropna().astype(str).unique())\n",
        "\n",
        "# ['0.5', '1', '12', '2', '3', '30', '4', '5', '6', '7', '?', '\\xa0']\n",
        "```\n",
        "\n",
        "'?' and '\\xa0' must go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8OVUxHB-bH7"
      },
      "source": [
        "df.loc[[190, 3883, 3890], '# Kills'] = np.nan # were ?, \\xa0, \\xa0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELcAdOAj-UDP"
      },
      "source": [
        "## *Damage* and *Notes* columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruubADJq-plk"
      },
      "source": [
        "### Typos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bes_E1aqePHg"
      },
      "source": [
        "The process here is a bit more involved, because there are a lot of unique values. To find typos, I'm comparing each word from Damage and Notes against a [list](https://github.com/dwyl/english-words) of English words.\n",
        "\n",
        "```python\n",
        "with open('drive/MyDrive/words_dictionary.json') as f:\n",
        "  all_words = json.load(f)\n",
        "\n",
        "# Augment the dictionary with Critical Role jargon, names, and abbreviations.\n",
        "# 1 does not mean anything; it can be any value.\n",
        "special = {'allura': 1, 'aoo': 1, 'arbuckle' : 1, 'arkhan' : 1, 'arkhans': 1,\n",
        "           'avandras': 1, 'battleaxe': 1, 'behir' : 1, 'bigbys': 1, 'bloodaxe': 1,\n",
        "           'bloodseeking': 1, 'bludgeoningpiercing' : 1, 'bulette' : 1,\n",
        "           'cerkonos' : 1, 'clarota' : 1, 'cloaker': 1, 'critinclusive': 1,\n",
        "           'daxio' : 1, 'direbear' : 1, 'direwolf' : 1, 'dragonslayer': 1,\n",
        "           'dragonslaying': 1, 'duergar' : 1, 'dwarven': 1, 'efreeti' : 1,\n",
        "           'elephantkeyleth' : 1, 'erinyes' : 1, 'faneeater': 1, 'fassbender' : 1,\n",
        "           'fbwh': 1, 'feeblemind': 1, 'fenthras': 1, 'feymire' : 1,\n",
        "           'firebludgeoning' : 1, 'fireradiant' : 1, 'flameskull' : 1,\n",
        "           'flametongue': 1, 'fmc' : 1, 'fomorian': 1, 'gern': 1, 'ghurrix' : 1,\n",
        "           'gilmore' : 1, 'gloomstalker' : 1, 'greatsword': 1, 'greenbeard' : 1,\n",
        "           'gricks' : 1, 'groon': 1, 'gsof': 1, 'gwm': 1, 'halfdamage': 1,\n",
        "           'hdywtdt': 1, 'hotis' : 1, 'illithid' : 1, 'iotha' : 1, 'kashaw': 1,\n",
        "           'kaylie' : 1, 'kerrek': 1, 'kerrion' : 1, 'kevdak' : 1, 'keyleth': 1, \n",
        "           'kima': 1, 'kryyn' : 1, 'kvarn': 1, 'kynan' : 1, 'lboss': 1,\n",
        "           'lemure' : 1, 'lfe' : 1, 'lifestealing': 1, 'lizardfolk' : 1,\n",
        "           'longsword': 1, 'luska' : 1, 'mathmod': 1, 'metamagic': 1, 'minxy': 1,\n",
        "           'murghol' : 1, 'mythcarver': 1, 'nat': 1, 'nonlethal': 1, 'nonmagic': 1,\n",
        "           'nothic': 1, 'npc': 1, 'ogden' : 1, 'ogrillon' : 1, 'omg': 1,\n",
        "           'orog' : 1, 'orthax' : 1, 'otyugh' : 1, 'percy': 1, 'piercinglightning' : 1,\n",
        "           'planetar': 1, 'poisondagger': 1, 'potd': 1, 'pwat': 1, 'raishan' : 1,\n",
        "           'rimefang' : 1, 'ripley': 1, 'ripleys': 1, 'saundor' : 1, 'scanlan': 1,\n",
        "           'scanlans': 1, 'selfhealing': 1, 'silverlaced': 1, 'slashingnecrotic' : 1,\n",
        "           'slashingpsychic' : 1, 'slashingpsychicradiant' : 1, 'sprigg': 1,\n",
        "           'suda' : 1, 'sylas' : 1, 'symphior' : 1, 'taliesin': 1, 'tary': 1,\n",
        "           'taryon': 1, 'thorbir' : 1, 'thordak' : 1, 'thunderwave': 1, \n",
        "           'tiberius': 1, 'titanstone': 1, 'tova': 1, 'treant' : 1, 'ulara' : 1,\n",
        "           'umbrasyl' : 1, 'utugash' : 1, 'vax': 1, 'vaxildan': 1, 'vaxs': 1,\n",
        "           'vecna' : 1, 'vecnas': 1, 'velora' : 1, 'vex': 1, 'vexahlia': 1,\n",
        "           'vexs': 1, 'vorugal' : 1, 'vouk' : 1, 'warhammer': 1, 'witchbolt': 1,\n",
        "           'xanthas' : 1, 'yenk' : 1, 'zd': 1\n",
        "}\n",
        "\n",
        "all_words.update(special)\n",
        "\n",
        "def find_typos(column, all_words):\n",
        "  \"\"\"Returns cells from col_name that have words not in all_words.\"\"\"\n",
        "  for i, note in column.items():\n",
        "    if pd.notnull(note):\n",
        "      note = note.replace('\\n', ' ')\n",
        "      clean_note = ''.join(s for s in note if s.isalpha() or s == ' ' or s == '\\n')\n",
        "      for word in clean_note.split():\n",
        "        if word.lower() not in all_words:\n",
        "          print(i, note, word.lower())\n",
        "\n",
        "find_typos(df['Damage'], all_words)\n",
        "print()\n",
        "find_typos(df['Notes'], all_words)\n",
        "\n",
        "# >>> 746 Against Basilisk.Tiberius is Restrained basilisktiberius\n",
        "#     2457 17 Piercing to Ettin ettin\n",
        "#     4304 13 Psychic to Vax'idlan vaxidlan\n",
        "#     6388 29 to GB, Archer, Duid, 6 Baddies;  14 (29/2) to Kevdak gb\n",
        "#     6388 29 to GB, Archer, Duid, 6 Baddies;  14 (29/2) to Kevdak duid\n",
        "#     8898 23 to Wyvern, 11 to Rder rder\n",
        "#     ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb4jjKDLohy1"
      },
      "source": [
        "Introducing abbreviated monster names does not seem like a good idea. It causes two problems:\n",
        "1. One entity can have two names (e.g. Smelter Guardian 1 and SG1 are both present in the table, but they are the same monster).\n",
        "1. Two entities can have the same name (e.g. A1 is both Archer 1 and Assassin 1).\n",
        "\n",
        "I decided to replace, with a few exceptions (HP, NPC, HDYWTDT), all abbreviations.\n",
        "\n",
        "To find them I went through all short tokens (lengths 2, 3, 4):\n",
        "```python\n",
        "for length in [2, 3, 4]:\n",
        "  lst = []\n",
        "  for s in df['Damage'].astype(str):\n",
        "    lst.extend(token for token in s.split() \n",
        "                     if len(token) == length\n",
        "                        and not token.isnumeric()\n",
        "              )\n",
        "  for s in df['Notes'].astype(str):\n",
        "    lst.extend(token for token in s.split() \n",
        "                     if len(token) == length\n",
        "                        and not token.isnumeric()\n",
        "              )\n",
        "  print(sorted(set(lst)))\n",
        "\n",
        "# >>>\n",
        "# [..., '5]', '7]', '8,', '9!', '9)', '9?', '??', 'A1', 'A2', 'A3', 'AH', 'AP', 'As', 'B1', 'B2', ...]\n",
        "# [..., '>8,', 'A1,', 'AE1', 'AE2', 'AH,', 'AP,', 'Air', 'All', 'AoO', 'Arm', 'Axe', 'BB)', 'BB]', ...]\n",
        "# [..., 'Edge', 'Elf,', 'Eyes', 'FAIL', 'FBWH', 'FE2,', 'FG1)', 'FG2)', ...]\n",
        "```\n",
        "\n",
        "Code that makes corrections:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be5nZwlpKcbG"
      },
      "source": [
        "# SS can mean Small Salamander and Sharpshooter.\n",
        "# Here, I replace SS here with Small Salamander; later, with Sharpshooter.\n",
        "df.loc[[5470, 5493], 'Damage'].replace(regex={'SS' : 'Small Salamander'},\n",
        "                                       inplace=True\n",
        "                                      )\n",
        "\n",
        "# Replace a single occurrence of FA:\n",
        "df.loc[5493, 'Damage'] = \\\n",
        "  df.loc[5493, 'Damage'].replace('FA', 'Fatty Arbuckle')\n",
        "\n",
        "# Targeted replacement of Cass with Cassandra, so that I don't get \"Cassandraandra\". \n",
        "df.loc[[3843, 3846, 4127, 4171, 4172],\n",
        "       ['Damage', 'Notes']\n",
        "      ].replace(\n",
        "                regex={'Cass' : 'Cassandra'},\n",
        "                inplace=True\n",
        "               )\n",
        "\n",
        "# \"A\" can mean Archer and Assassin.\n",
        "# Here, I replace \"A\" here with Archer; later, with Assassin.\n",
        "df.loc[6280:6414, ['Damage', 'Notes']] = \\\n",
        "  df.loc[6280:6414, ['Damage', 'Notes']].replace(regex={'A1' : 'Archer 1',\n",
        "                                                        'A2' : 'Archer 2'\n",
        "                                                       }, \n",
        "                                                )\n",
        "\n",
        "# FG can mean Frost Giant and Fire Giant.\n",
        "# Here, I replace FG here with Frost Giant; later, with Fire Giant.\n",
        "df.loc[1943:2123, ['Damage', 'Notes']] = \\\n",
        "  df.loc[1943:2123, ['Damage', 'Notes']].replace(regex={'FG1' : 'Frost Giant 1',\n",
        "                                                        'FG2' : 'Frost Giant 2'\n",
        "                                                       }, \n",
        "                                                )\n",
        "\n",
        "# G1 is present in G1, as Guard 1, and in SG1, as Smelter Guardian 1.\n",
        "# Here, I replace G with Guard; later, I replace SG with Smelter Guardian.\n",
        "df.loc[3225:3651, ['Damage', 'Notes']] = \\\n",
        "  df.loc[3225:3651, ['Damage', 'Notes']].replace(regex={'G1' : 'Guard 1',\n",
        "                                                        'G2' : 'Guard 2',\n",
        "                                                        'G3' : 'Guard 3',\n",
        "                                                        'G4' : 'Guard 4',\n",
        "                                                        'G5' : 'Guard 5',\n",
        "                                                        'G6' : 'Guard 6',\n",
        "                                                        'G8' : 'Guard 8',\n",
        "                                                       },\n",
        "                                                )\n",
        "# Correcting typos in Damage:\n",
        "damage_typos = {  \n",
        "  '\\xa0' : ' ',\n",
        "  'Basilisk.Tiberius' : 'Basilisk. Tiberius',\n",
        "  'Budgeoning' : 'Bludgeoning',\n",
        "  'Cassnadra' : 'Cassandra',\n",
        "  'Duid' : 'Druid',\n",
        "  'Gloomtalker' : 'Gloomstalker',\n",
        "  'Gog' : 'Grog',\n",
        "  'LFe' : 'LFE',\n",
        "  'Lightnint' : 'Lightning',\n",
        "  'Rder' : 'Rider',\n",
        "  'Sanlan' : 'Scanlan',\n",
        "  'utugash' : 'Utugash',\n",
        "  \"Vax'idlan\" : \"Vax'ildan\",\n",
        "  'Vaxildan' : \"Vax'ildan\",\n",
        "}\n",
        "\n",
        "df['Damage'].replace(regex=damage_typos, inplace=True)\n",
        "\n",
        "# Correcting typos in Notes:\n",
        "notes_typos = {\n",
        "  '-HDYWTDT' : ' - HDYWTDT',\n",
        "  \"Arkan's\" : \"Arkhan's\",\n",
        "  'Blde' : 'Blade',\n",
        "  'Celing' : 'Ceiling',\n",
        "  'constituion' : 'constitution',\n",
        "  'Dimunition' : 'Diminution',\n",
        "  'disadvantaqge' : 'disadvantage',\n",
        "  'disdavantage' : 'disadvantage',\n",
        "  'disdvantage' : 'disadvantage',\n",
        "  'ddvantage' : 'advantage',\n",
        "  'Ensare' : 'Ensnare',\n",
        "  'Envervate' : 'Enervate',\n",
        "  'HDYTWDT' : 'HDYWTDT',\n",
        "  'healls' : 'heals',\n",
        "  'Mindcontrolled' : 'Mind-controlled',\n",
        "  'Opportunity-Punch' : 'Opportunity - Punch',\n",
        "  'Possesssed' : 'Possessed',\n",
        "  'posessed' : 'possessed',\n",
        "  'proficent' : 'proficient',\n",
        "  'PWAT' : 'PWaT',\n",
        "  'PWT' : 'PWaT',\n",
        "  'Reckles ' : 'Reckless',\n",
        "  'Rckless' : 'Reckless',\n",
        "  'Recklesss' : 'Reckless',\n",
        "  'Spritiual' : 'Spiritual',\n",
        "  'Spritual' : 'Spiritual',\n",
        "  'suceeds' : 'succeeds',\n",
        "  'Suprise' : 'Surprise',\n",
        "  'Surpise' : 'Surprise',\n",
        "  'Throns' : 'Thorns',\n",
        "  'telekineis' : 'telekinesis',\n",
        "  'Titanstonke' : 'Titanstone',\n",
        "  'toadvantage' : 'to advantage',\n",
        "  'Wihout' : 'Without',\n",
        "  'Wirh' : 'With',\n",
        "  'Wounds-Scanlan' : 'Wounds - Scanlan',\n",
        "  \"Wounds-Vax'ildan\" : \"Wounds - Vax'ildan\",\n",
        "  'Unnanounced' : 'Unannounced',\n",
        "  'unnanounced' : 'unannounced',\n",
        "}\n",
        "\n",
        "df['Notes'].replace(regex=notes_typos, inplace=True)\n",
        "\n",
        "# Replace abbreviations\n",
        "abbreviations = {\n",
        "  '2H' : '2-handed',\n",
        "  'AoO' : 'Attack of Opportunity',\n",
        "  'A1' : 'Assassin 1',\n",
        "  'A2' : 'Assassin 2',\n",
        "  'A3' : 'Assassin 3',\n",
        "  'AE' : 'Air Elemental',\n",
        "  'AH' : 'Adamantine Hammer',\n",
        "  'AP' : 'Archpriest',\n",
        "  'B1' : 'Basilisk 1',\n",
        "  'B2' : 'Basilisk 2',\n",
        "  'B3' : 'Basilisk 3',\n",
        "  'B4' : 'Basilisk 4',\n",
        "  'B5' : 'Basilisk 5',\n",
        "  'BB' : 'Blazing Bowstring',\n",
        "  'BN' : 'Bad News',\n",
        "  'CE' : 'Craven Edge',\n",
        "  'CG' : 'Cobalt Golem',\n",
        "  'DoV' : 'Dagger of Venom',\n",
        "  'DS' : 'Divine Smite',\n",
        "  'FBWH' : 'Firebrand Warhammer',\n",
        "  'EE' : 'Earth Elemental',\n",
        "  'FE1' : 'Fire Elemental 1',\n",
        "  'FE2' : 'Fire Elemental 2',\n",
        "  'FE3' : 'Fire Elemental 3',\n",
        "  'FG1' : 'Fire Giant 1',\n",
        "  'FG2' : 'Fire Giant 2',\n",
        "  'FG' : 'Fire Giant ',\n",
        "  'FMC' : 'Feymire Crocodile',\n",
        "  'FS' : 'Flameskull',\n",
        "  'GB' : 'Greenbeard',\n",
        "  'GSoF' : 'Greatsword of Frenzy',\n",
        "  'GWM' : 'Great Weapon Master',\n",
        "  'HM' : \"Hunter's Mark\",\n",
        "  'KT' : 'Kuo-toa ',\n",
        "  'L1' : 'Looter 1',\n",
        "  'L2' : 'Looter 2',\n",
        "  'L3' : 'Looter 3',\n",
        "  'L4' : 'Looter 4',\n",
        "  'L5' : 'Looter 5',\n",
        "  'L6' : 'Looter 6',\n",
        "  'L7' : 'Looter 7',\n",
        "  'L8' : 'Looter 8',\n",
        "  'L9' : 'Looter 9',\n",
        "  'LBoSS' : 'Longbow of Sky Sentinel',\n",
        "  'LFE' : 'Large Fire Elemental',\n",
        "  'LS' : 'Large Salamander',\n",
        "  'PotD' : 'Plate of the Dawnmartyr',\n",
        "  'PWaT' : 'Pass Without a Trace',\n",
        "  'R1' : 'Rider 1',\n",
        "  'R2' : 'Rider 2',\n",
        "  'R3' : 'Rider 3',\n",
        "  'R4' : 'Rider 4',\n",
        "  'R5' : 'Rider 5',\n",
        "  'R6' : 'Rider 6',\n",
        "  'R7' : 'Rider 7',\n",
        "  'R8' : 'Rider 8',\n",
        "  'RT' : 'Reliable Talent',\n",
        "  'SA' : 'Sneak Attack',\n",
        "  'SFE' : 'Small Fire Elemental',\n",
        "  'SG1' : 'Smelter Guardian 1',\n",
        "  'SG2' : 'Smelter Guardian 2',\n",
        "  'SG3' : 'Smelter Guardian 3',\n",
        "  'SG' : 'Smelter Guardian',\n",
        "  'SM' : 'Stitch Monster',\n",
        "  'SS' : 'Sharpshooter',\n",
        "  'T1' : 'Troll 1',\n",
        "  'T2' : 'Troll 2',\n",
        "  'T3' : 'Troll 3',\n",
        "  'VM' : 'Vox Machina',\n",
        "  'VS' : 'Vampire Spawn',\n",
        "  'W1' : 'Wyvern 1',\n",
        "  'W2' : 'Wyvern 2',\n",
        "  'W3' : 'Wyvern 3',\n",
        "  'W4' : 'Wyvern 4', \n",
        "  'WM2' : 'War Monger 2',\n",
        "  'WM3' : 'War Monger 3',\n",
        "  'w/' : 'with',\n",
        "  'ZD' : 'Zombie Dwarf'\n",
        "}\n",
        "\n",
        "# df['Damage'].replace(regex=abbreviations, inplace=True)\n",
        "# df['Notes'].replace(regex=abbreviations, inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebeOkuK1-vii"
      },
      "source": [
        "### Cleaning up advantages and disadvantages in Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n_j8TvU_BXJ"
      },
      "source": [
        "I have noticed several problems regarding rolls with advantage or disadvantage:\n",
        "1. Sometimes there is a mismatch between two rolls from a pair: according to Notes, one roll is at advantage and the other is at disadvantage.\n",
        "2. Sometimes only one of rolls from a pair is marked in Notes. I call them _orphans_.\n",
        "\n",
        "The code below finds the mismatches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liIqq6izCTSq"
      },
      "source": [
        "def find_orphan(mask):\n",
        "  \"\"\"Returns positions of orphans given a mask.\n",
        "     An orphan is a **single** True surrounded by two Falses.\n",
        "  \"\"\"\n",
        "\n",
        "  mask_1_forward = np.roll(mask.to_numpy(), 1)\n",
        "  mask_1_backwards = np.roll(mask.to_numpy(), -1)\n",
        "  has_neighbors_mask = mask & mask_1_forward | mask & mask_1_backwards\n",
        "  is_orphan_mask = mask & ~has_neighbors_mask\n",
        "  return np.where(is_orphan_mask)[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VukOwje3FbiN"
      },
      "source": [
        "```python\n",
        "disadv_mask = (df['Notes'].str.contains('disadvantage').fillna(False)\n",
        "             | df['Notes'].str.contains('Disadvantage').fillna(False)\n",
        ")\n",
        "adv_mask = ((df['Notes'].str.contains('advantage').fillna(False)\n",
        "             | df['Notes'].str.contains('Advantage').fillna(False)\n",
        "            )\n",
        "            & ~disadv_mask\n",
        ")\n",
        "\n",
        "adv_orphan = find_orphan(adv_mask)\n",
        "disadv_orphan = find_orphan(disadv_mask)\n",
        "\n",
        "# Find rows where orphan advantage and orphan disadvantage are neighbors:\n",
        "adv_disadv_mismatch = np.sort(np.concatenate((adv_orphan, disadv_orphan)))\n",
        "idx = adv_disadv_mismatch[adv_disadv_mismatch == np.roll(adv_disadv_mismatch-1, -1)]\n",
        "\n",
        "# Print mismatching rolls and their neighbors:\n",
        "print(df[['Episode',\n",
        "          'Time',\n",
        "          'Character',\n",
        "          'Type of Roll',\n",
        "          'Natural Value',\n",
        "          'Notes'\n",
        "         ]\n",
        "        ].iloc[np.sort(np.concatenate((idx-1, idx, idx+1)))])\n",
        "\n",
        "# >>>\n",
        "# 300         4  1:34:00  Vax'ildan         Acrobatics             5                                         NaN\n",
        "# 301         4  1:36:40    Scanlan            Stealth       Unknown             Disregarded due to disadvantage\n",
        "# 302         4  1:36:40    Scanlan            Stealth            11                              With advantage\n",
        "# 782         7  3:09:26   Tiberius  Constitution Save           NaN                                 Unknown mod\n",
        "# 783         7  3:09:32      Percy             Attack       Unknown                Disregarded due to advantage\n",
        "# 784         7  3:09:32      Percy             Attack             5                 Pepperbox with Disadvantage\n",
        "# ...\n",
        "# 13116     113  4:17:09       Pike          Dexterity             4                                         NaN\n",
        "# 13117     113  4:19:25    Scanlan      Charisma Save       Unknown             Disregarded due to disadvantage\n",
        "# 13118     113  4:19:25    Scanlan      Charisma Save             8                   Scanlan 1, With advantage\n",
        "# 13339     114  3:26:18  Vax'ildan             Damage           NaN                                         NaN\n",
        "# 13340     114  3:27:17  Vax'ildan             Attack       Unknown  Disregarded due to disadvantage with Bless\n",
        "# 13341     114  3:27:17  Vax'ildan             Attack       Unknown           Whisper with advantage with Bless\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WESK7lu2AsQa"
      },
      "source": [
        "# Correcting mismatching advantage and disadvantage for a roll:\n",
        "\n",
        "to_adv_list = [301, 2987, 2989, 2991, 7327, 12146, 13117, 13340]\n",
        "df.loc[to_adv_list, 'Notes'] = \\\n",
        "  df.loc[to_adv_list, 'Notes'].replace(regex={'disadvantage' : 'advantage'})                                 \n",
        "                                     \n",
        "to_disadv_list = [783, 857, 1466, 2625, 3629, 4483, 4487]\n",
        "df.loc[to_disadv_list, 'Notes'] = \\\n",
        "  df.loc[to_disadv_list, 'Notes'].replace(regex={'advantage' : 'disadvantage'})"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCV_jMlgP15D"
      },
      "source": [
        "#### Adding missing remarks on having advantage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4njqaVJWMOMP"
      },
      "source": [
        "For some reason, almost always it is _With advantage_ remark that is missing, while _Disregarded due to advantage_ is present.\n",
        "\n",
        "Whenever a note mentions advantage but either no rolls were made or only one was made, I shorten advantage to disadv. (Because this is the same as a straight roll, and, for my own project, I need a way to filter rolls at advantage and disadvatage.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntn-gF2Aifah"
      },
      "source": [
        "# Special cases with no pattern:\n",
        "df.loc[9478:9532:2, 'Notes'] += ' (with advantage)'\n",
        "df.loc[[1531, 3343, 6305, 8149, 8151, 11854], 'Notes'] += ' (with advantage)'\n",
        "df.loc[[5104, 8300, 11183, 11383, 11402, 13209], 'Notes'] += 'and advantage'\n",
        "\n",
        "df.loc[1527, 'Notes'] = ''\n",
        "df.loc[3212, 'Notes'] = 'With advantage, disregarded due to Luck'\n",
        "df.loc[3393, 'Notes'] = 'Pepperbox Sharpshooter Ice (adv. not rolled)'\n",
        "df.loc[4743, 'Notes'] = 'Craven Edge GWM Reckless Attack (with advantage) - Frost Worm dies - HDYWTDT'\n",
        "df.loc[[4918, 4945, 4947], 'Notes'] = 'Craven Edge Great Weapon Master Reckless Attack (with advantage), Grog gains +1 Strength'\n",
        "df.loc[7195, 'Notes'] = \"Bad News Deadeye Sharpshooter (adv. not rolled)\"\n",
        "df.loc[8153, 'Notes'] = \"Bloodaxe Great Weapon Master Reckless Attack (with advantage), slices through Ripley's midsection\"\n",
        "df.loc[9835, 'Notes'] = 'With Luck'\n",
        "df.loc[10698, 'Notes'] = 'Against Cage drop (with advantage), Grog is restrained'\n",
        "df.loc[11393, 'Notes'] = 'With Pass Without a Trace and advantage, bad math/mod or unannounced nat20'\n",
        "df.loc[11943, 'Notes'] = 'Adv. not rolled'\n",
        "df.loc[13320, 'Notes'] = 'Whisper Sneak Attack of Opportunity with Divine Smite, Bless, and advantage'\n",
        "df.loc[13447, 'Notes'] = 'Sword of Kas Reckless'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvXoJcKaXkuG"
      },
      "source": [
        "disadv_mask = (df['Notes'].str.contains('disadvantage').fillna(False)\n",
        "             | df['Notes'].str.contains('Disadvantage').fillna(False)\n",
        ")\n",
        "adv_mask = ((df['Notes'].str.contains('advantage').fillna(False)\n",
        "             | df['Notes'].str.contains('Advantage').fillna(False)\n",
        "            )\n",
        "            & ~disadv_mask\n",
        ")\n",
        "\n",
        "adv_orphan = find_orphan(adv_mask)\n",
        "disadv_orphan = find_orphan(disadv_mask)\n",
        "\n",
        "# Special cases; not orphans\n",
        "not_orphan_idx = np.where(np.isin(adv_orphan, \n",
        "                                  [202, 204, 3343, 3346, 11170, 13289, 13291]))\n",
        "adv_orphan = np.delete(adv_orphan, not_orphan_idx)\n",
        "\n",
        "# Among orphaned advantages:\n",
        "for i in adv_orphan:\n",
        "  # If the previous line has matching Time, Character, Type of Roll:\n",
        "  if (df.loc[i, ['Time', 'Character', 'Type of Roll']] \n",
        "      == df.loc[i-1, ['Time', 'Character', 'Type of Roll']]\n",
        "     ).all():\n",
        "    # If the cell is empty, fill it:\n",
        "    if pd.isna(df.loc[i-1, 'Notes']):\n",
        "      df.loc[i-1, 'Notes'] = 'With advantage'\n",
        "    # Otherwise, add ' (with disadvantage)' to the note:\n",
        "    else:\n",
        "      df.loc[i-1, 'Notes'] += ' (with advantage)'\n",
        "\n",
        "  # If the next line has matching Time, Character, Type of Roll:\n",
        "  if (df.loc[i, ['Time', 'Character', 'Type of Roll']] \n",
        "      == df.loc[i+1, ['Time', 'Character', 'Type of Roll']]\n",
        "     ).all():\n",
        "    # If the cell is empty, fill it:\n",
        "    if pd.isna(df.loc[i+1, 'Notes']):\n",
        "      df.loc[i+1, 'Notes'] = 'With advantage'\n",
        "    # Otherwise, add ' (with disadvantage)' to the note:  \n",
        "    else:\n",
        "      df.loc[i+1, 'Notes'] += ' (with advantage)'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G9vsXOHeqvH"
      },
      "source": [
        "#### Filling missing remarks on disadvantage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85DyYMUfMxue"
      },
      "source": [
        "For some reason, almost always it is _With disadvantage_ remark that is missing, while _Disregarded due to disadvantage_ is present.\n",
        "\n",
        "Whenever a note mentions disadvantage but either no rolls were made or only one was made, I shorten disadvantage to disadv. (Because this is the same as a straight roll, and, for my own project, I need a way to filter rolls at advantage and disadvatage.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZr7IMATh5m-"
      },
      "source": [
        "# Special cases with no pattern:\n",
        "df.loc[[854, 860, 1110, 1467, 1469], 'Notes'] += ' with disadvantage'\n",
        "df.loc[[5752, 5754, 5756], 'Notes'] += ' (was rolled with disadvantage)'\n",
        "df.loc[10256, 'Notes'] = 'Whisper with disadvantage and Bless'\n",
        "\n",
        "df.loc[2785, 'Notes'] = 'Sylas has disadv. on all attacks'\n",
        "df.loc[3095, 'Notes'] = 'Behir has disadv.'\n",
        "df.loc[3777, 'Notes'] = 'Has disadv. on Dexterity Ability Checks'\n",
        "df.loc[5767, 'Notes'] = 'Arrow, No disadv. due to Guiding Bolt'\n",
        "df.loc[6379, 'Notes'] = 'Disadv. not rolled'\n",
        "df.loc[6935, 'Notes'] = 'Longbow of Sky Sentinel (disadv. not rolled)'\n",
        "df.loc[4321, 'Notes'] = 'Cutting Words, has disadv. on next attack'\n",
        "df.loc[9993, 'Notes'] = 'Dagger of Venom (disadv. not rolled)'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nTTP4fKtyic"
      },
      "source": [
        "disadv_mask = (df['Notes'].str.contains('disadvantage').fillna(False)\n",
        "             | df['Notes'].str.contains('Disadvantage').fillna(False)\n",
        ")\n",
        "disadv_orphan = find_orphan(disadv_mask)\n",
        "\n",
        "# Special cases; not orphans:\n",
        "not_orphan_idx = np.where(np.isin(disadv_orphan, [601, 605, 6608, 10179, 10181, 10251, 10253, 13244, 13246])) # special cases; not orphans\n",
        "disadv_orphan = np.delete(disadv_orphan, not_orphan_idx)\n",
        "\n",
        "# Among orphaned disadvantages:\n",
        "for i in disadv_orphan:\n",
        "  # If the previous line has matching Time, Character, Type of Roll:\n",
        "  if (df.loc[i, ['Time', 'Character', 'Type of Roll']] \n",
        "      == df.loc[i-1, ['Time', 'Character', 'Type of Roll']]\n",
        "     ).all():\n",
        "    # If the cell is empty, fill it:\n",
        "    if pd.isna(df.loc[i-1, 'Notes']):\n",
        "      df.loc[i-1, 'Notes'] = 'With disadvantage'\n",
        "    else:\n",
        "      df.loc[i-1, 'Notes'] += ' (with disadvantage)'\n",
        "\n",
        "  # If the next line has matching Time, Character, Type of Roll:\n",
        "  if (df.loc[i, ['Time', 'Character', 'Type of Roll']] \n",
        "      == df.loc[i+1, ['Time', 'Character', 'Type of Roll']]\n",
        "     ).all():\n",
        "    # If the cell is empty, fill it:\n",
        "    if pd.isna(df.loc[i+1, 'Notes']):\n",
        "      df.loc[i+1, 'Notes'] = 'With disadvantage'\n",
        "    # Otherwise, add ' (with disadvantage)' to the note:\n",
        "    else:\n",
        "      df.loc[i+1, 'Notes'] += ' (with disadvantage)'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX8CG1EDRGKv"
      },
      "source": [
        "## Insert rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9sBno8TRR73"
      },
      "source": [
        "# Add a row for a missing advantage counterpart:\n",
        "line = pd.DataFrame({\n",
        "    'Episode': 'C1E004',\n",
        "    'Time' : '1:46:22',\n",
        "    'Character' : \"Vax'ildan\",\n",
        "    'Type of Roll' : 'Attack',\n",
        "    'Total Value' : 'Unknown',\n",
        "    'Natural Value' : 'Unknown',\n",
        "    'Crit?' : '',\n",
        "    'Damage' : '',\n",
        "    '# Kills' : '',\n",
        "    'Notes' : 'Disregarded due to advantage',\n",
        "    }, index=[315.5]\n",
        ")\n",
        "df = df.append(line, ignore_index=False)\n",
        "\n",
        "line = pd.DataFrame({\n",
        "    'Episode': 'C1E108',\n",
        "    'Time' : '0:47:35',\n",
        "    'Character' : \"Grog\",\n",
        "    'Type of Roll' : 'Attack',\n",
        "    'Total Value' : '25',\n",
        "    'Natural Value' : '14',\n",
        "    'Crit?' : '',\n",
        "    'Damage' : '',\n",
        "    '# Kills' : '',\n",
        "    'Notes' : 'Disregarded due to advantage',\n",
        "    }, index=[12117.5]\n",
        ")\n",
        "df = df.append(line, ignore_index=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmtNoDomhOUD"
      },
      "source": [
        "## Delete rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rGR58X3hNC2"
      },
      "source": [
        "# Row 1838 is a dexterity save for monsters, rolled by the DM:\n",
        "df.drop(1838, inplace=True)\n",
        "# Row 4129 is a duplicate of row 4135:\n",
        "df.drop(4129, inplace=True)\n",
        "# Drop empty rows in the middle of the table:\n",
        "df.drop(np.arange(7244, 7249), inplace=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-bmM34CzqvC"
      },
      "source": [
        "## Miscellaneous corrections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWmRZbmIz0v7"
      },
      "source": [
        "Found randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elvXOm25mVpB"
      },
      "source": [
        "# AoE damage from 2 Fireballs, brought where they belong to:\n",
        "df.loc[1829, 'Damage'] = ('41 Fire to Hydra, 22 (41/2) Fire to Grog, '\n",
        "                          + '22 (41/2) Fire to Trinket, 41 Fire to 4 Others, '\n",
        "                          + '22 (41/2) Fire to 1 Other'\n",
        ")\n",
        "df.loc[1830, 'Damage'] = (\"39 Fire to Hydra, 18 (39/2) Fire to Vax'ildan, \"\n",
        "                          + '39 Fire to Grog, 39 Fire to Trinket, '\n",
        "                          + '39 Fire to 5 Others'\n",
        ")\n",
        "df.loc[1831:1837] = np.nan\n",
        "\n",
        "# Was Arcana for some reason:\n",
        "df.loc[5433, 'Type of Roll'] = 'Alchemy'\n",
        "# Found a couple of missing critical hits:\n",
        "df.loc[[12431, 12434], 'Crit ?'] = 'Y'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xbAvOn5j36z"
      },
      "source": [
        "## Sort by *Episode*, *Time*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n4AYVqCj98W"
      },
      "source": [
        "df.sort_values(['Episode', 'Time'], inplace=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej3om4jthhaW"
      },
      "source": [
        "## Mild to strict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udPDRxQU2B87"
      },
      "source": [
        "df_mild = df.reset_index(drop=True)\n",
        "\n",
        "# Expand abbreviations (abbreviations are defined in the *Damage and Notes* section):\n",
        "df['Damage'].replace(regex=abbreviations, inplace=True)\n",
        "df['Notes'].replace(regex=abbreviations, inplace=True)\n",
        "\n",
        "# Rows 3032, 3324 are notes on a missing audio/video:\n",
        "df.drop([3032, 3324], inplace=True)\n",
        "\n",
        "# Replace \\n with whitespace:\n",
        "df.loc[:, ['Damage', 'Notes']] = \\\n",
        "  df.loc[:, ['Damage', 'Notes']].replace(regex={'\\n' : ' '})\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_mild.to_csv('Mildly_Cleanish_All_Rolls_TalDorei.csv', index=False)  \n",
        "df.to_csv('Strictly_Cleanish_All_Rolls_TalDorei.csv', index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}